res = BMC(f,D,T,prior,w)
Ef[t] = res$mean
Vf[t] = res$var
}
Ef
plot(T_vec,abs(Ef-int))
=4; prior = list(b = rep(0,D), B = diag(D)); w = c(1,rep(3.5,D));
T_vec = round(seq(10,100,length.out=20)) # number of samples
mu= rep(0,D); Sigma = diag(D)
f = function(x) dmvnorm(x,mean=mu,sigma=Sigma)
M = solve(solve(Sigma) + solve(prior$B))
b = t((t(mu) %*% solve(Sigma) + t(prior$b) %*% solve(prior$B)) %*% M)
int = sqrt(det(M)/(2*pi*det(Sigma)*det(prior$B))) * exp(0.5*t(b) %*% solve(M) %*% b - 0.5*t(mu) %*% solve(Sigma) %*% mu
- 0.5*t(prior$b) %*% solve(prior$B) %*% prior$b )
Ef = c(); Vf = c()
for (t in 1:length(T_vec)) {
T = T_vec[t]
res = BMC(f,D,T,prior,w)
Ef[t] = res$mean
Vf[t] = res$var
}
Ef
plot(T_vec,abs(Ef-int))
D=4; prior = list(b = rep(0,D), B = diag(D)); w = c(1,rep(5,D));
T_vec = round(seq(10,100,length.out=20)) # number of samples
mu= rep(0,D); Sigma = diag(D)
f = function(x) dmvnorm(x,mean=mu,sigma=Sigma)
M = solve(solve(Sigma) + solve(prior$B))
b = t((t(mu) %*% solve(Sigma) + t(prior$b) %*% solve(prior$B)) %*% M)
int = sqrt(det(M)/(2*pi*det(Sigma)*det(prior$B))) * exp(0.5*t(b) %*% solve(M) %*% b - 0.5*t(mu) %*% solve(Sigma) %*% mu
- 0.5*t(prior$b) %*% solve(prior$B) %*% prior$b )
Ef = c(); Vf = c()
for (t in 1:length(T_vec)) {
T = T_vec[t]
res = BMC(f,D,T,prior,w)
Ef[t] = res$mean
Vf[t] = res$var
}
plot(T_vec,abs(Ef-int))
Ef
D=4; prior = list(b = rep(0,D), B = diag(D)); w = c(1,rep(4,D));
T_vec = round(seq(10,100,length.out=20)) # number of samples
mu= rep(0,D); Sigma = diag(D)
f = function(x) dmvnorm(x,mean=mu,sigma=Sigma)
M = solve(solve(Sigma) + solve(prior$B))
b = t((t(mu) %*% solve(Sigma) + t(prior$b) %*% solve(prior$B)) %*% M)
int = sqrt(det(M)/(2*pi*det(Sigma)*det(prior$B))) * exp(0.5*t(b) %*% solve(M) %*% b - 0.5*t(mu) %*% solve(Sigma) %*% mu
- 0.5*t(prior$b) %*% solve(prior$B) %*% prior$b )
Ef = c(); Vf = c()
for (t in 1:length(T_vec)) {
T = T_vec[t]
res = BMC(f,D,T,prior,w)
Ef[t] = res$mean
Vf[t] = res$var
}
Ef
plot(T_vec,abs(Ef-int))
D=4; prior = list(b = rep(0,D), B = diag(D)); w = c(1,rep(3.5,D));
T_vec = round(seq(10,100,length.out=20)) # number of samples
mu= rep(0,D); Sigma = diag(D)
f = function(x) dmvnorm(x,mean=mu,sigma=Sigma)
M = solve(solve(Sigma) + solve(prior$B))
b = t((t(mu) %*% solve(Sigma) + t(prior$b) %*% solve(prior$B)) %*% M)
int = sqrt(det(M)/(2*pi*det(Sigma)*det(prior$B))) * exp(0.5*t(b) %*% solve(M) %*% b - 0.5*t(mu) %*% solve(Sigma) %*% mu
- 0.5*t(prior$b) %*% solve(prior$B) %*% prior$b )
Ef = c(); Vf = c()
for (t in 1:length(T_vec)) {
T = T_vec[t]
res = BMC(f,D,T,prior,w)
Ef[t] = res$mean
Vf[t] = res$var
}
Ef
T_vec
plot(T_vec,abs(Ef-int))
D=4; prior = list(b = rep(0,D), B = diag(D)); w = c(1,rep(3,D));
T_vec = round(seq(10,100,length.out=20)) # number of samples
mu= rep(0,D); Sigma = diag(D)
f = function(x) dmvnorm(x,mean=mu,sigma=Sigma)
M = solve(solve(Sigma) + solve(prior$B))
b = t((t(mu) %*% solve(Sigma) + t(prior$b) %*% solve(prior$B)) %*% M)
int = sqrt(det(M)/(2*pi*det(Sigma)*det(prior$B))) * exp(0.5*t(b) %*% solve(M) %*% b - 0.5*t(mu) %*% solve(Sigma) %*% mu
- 0.5*t(prior$b) %*% solve(prior$B) %*% prior$b )
Ef = c(); Vf = c()
for (t in 1:length(T_vec)) {
T = T_vec[t]
res = BMC(f,D,T,prior,w)
Ef[t] = res$mean
Vf[t] = res$var
}
Ef
plot(T_vec,abs(Ef-int))
D=4; prior = list(b = rep(0,D), B = diag(D)); w = c(1,rep(2.5,D));
T_vec = round(seq(10,100,length.out=20)) # number of samples
mu= rep(0,D); Sigma = diag(D)
f = function(x) dmvnorm(x,mean=mu,sigma=Sigma)
M = solve(solve(Sigma) + solve(prior$B))
b = t((t(mu) %*% solve(Sigma) + t(prior$b) %*% solve(prior$B)) %*% M)
int = sqrt(det(M)/(2*pi*det(Sigma)*det(prior$B))) * exp(0.5*t(b) %*% solve(M) %*% b - 0.5*t(mu) %*% solve(Sigma) %*% mu
- 0.5*t(prior$b) %*% solve(prior$B) %*% prior$b )
Ef = c(); Vf = c()
for (t in 1:length(T_vec)) {
T = T_vec[t]
res = BMC(f,D,T,prior,w)
Ef[t] = res$mean
Vf[t] = res$var
}
Ef
plot(T_vec,abs(Ef-int))
D=4; prior = list(b = rep(0,D), B = diag(D)); w = c(1,rep(2,D));
T_vec = round(seq(10,100,length.out=20)) # number of samples
mu= rep(0,D); Sigma = diag(D)
f = function(x) dmvnorm(x,mean=mu,sigma=Sigma)
M = solve(solve(Sigma) + solve(prior$B))
b = t((t(mu) %*% solve(Sigma) + t(prior$b) %*% solve(prior$B)) %*% M)
int = sqrt(det(M)/(2*pi*det(Sigma)*det(prior$B))) * exp(0.5*t(b) %*% solve(M) %*% b - 0.5*t(mu) %*% solve(Sigma) %*% mu
- 0.5*t(prior$b) %*% solve(prior$B) %*% prior$b )
Ef = c(); Vf = c()
for (t in 1:length(T_vec)) {
T = T_vec[t]
res = BMC(f,D,T,prior,w)
Ef[t] = res$mean
Vf[t] = res$var
}
plot(T_vec,abs(Ef-int))
D=4; prior = list(b = rep(0,D), B = diag(D)); w = c(1,rep(2.3,D));
T_vec = round(seq(10,100,length.out=20)) # number of samples
mu= rep(0,D); Sigma = diag(D)
f = function(x) dmvnorm(x,mean=mu,sigma=Sigma)
M = solve(solve(Sigma) + solve(prior$B))
b = t((t(mu) %*% solve(Sigma) + t(prior$b) %*% solve(prior$B)) %*% M)
int = sqrt(det(M)/(2*pi*det(Sigma)*det(prior$B))) * exp(0.5*t(b) %*% solve(M) %*% b - 0.5*t(mu) %*% solve(Sigma) %*% mu
- 0.5*t(prior$b) %*% solve(prior$B) %*% prior$b )
Ef = c(); Vf = c()
for (t in 1:length(T_vec)) {
T = T_vec[t]
res = BMC(f,D,T,prior,w)
Ef[t] = res$mean
Vf[t] = res$var
}
Ef
plot(T_vec,abs(Ef-int))
D=4; prior = list(b = rep(0,D), B = diag(D)); w = c(1,rep(2.4,D));
T_vec = round(seq(10,100,length.out=20)) # number of samples
mu= rep(0,D); Sigma = diag(D)
f = function(x) dmvnorm(x,mean=mu,sigma=Sigma)
M = solve(solve(Sigma) + solve(prior$B))
b = t((t(mu) %*% solve(Sigma) + t(prior$b) %*% solve(prior$B)) %*% M)
int = sqrt(det(M)/(2*pi*det(Sigma)*det(prior$B))) * exp(0.5*t(b) %*% solve(M) %*% b - 0.5*t(mu) %*% solve(Sigma) %*% mu
- 0.5*t(prior$b) %*% solve(prior$B) %*% prior$b )
Ef = c(); Vf = c()
for (t in 1:length(T_vec)) {
T = T_vec[t]
res = BMC(f,D,T,prior,w)
Ef[t] = res$mean
Vf[t] = res$var
}
plot(T_vec,abs(Ef-int))
T_vec = round(seq(5,30,length.out=20)) # number of samples
mu= rep(0,D); Sigma = diag(D)
f = function(x) dmvnorm(x,mean=mu,sigma=Sigma)
M = solve(solve(Sigma) + solve(prior$B))
b = t((t(mu) %*% solve(Sigma) + t(prior$b) %*% solve(prior$B)) %*% M)
int = sqrt(det(M)/(2*pi*det(Sigma)*det(prior$B))) * exp(0.5*t(b) %*% solve(M) %*% b - 0.5*t(mu) %*% solve(Sigma) %*% mu
- 0.5*t(prior$b) %*% solve(prior$B) %*% prior$b )
Ef = c(); Vf = c()
for (t in 1:length(T_vec)) {
T = T_vec[t]
res = BMC(f,D,T,prior,w)
Ef[t] = res$mean
Vf[t] = res$var
}
plot(T_vec,abs(Ef-int))
Ef
b = prior$b; B = prior$B; A = diag(w[2:(D+1)])
kernel = function(x1,x2) {w[1]*exp(-1/2*sum(((x1-x2)/w[2:(D+1)])^2) )}
a = t(matrix(mvrnorm(n=T,b,B),T,D))
y = apply(a,2,f)
K = matrix(0,T,T)
for (i in 1:T) {
for (j in i:T) {
K[i,j] = kernel(a[,i],a[,j])
}
}
K = K + t(K) - Diagonal(T,diag(K))
a
y
x = t(a)
dim(x)
trueKern = kernCreate(x, list(type="cmpnd",comp=list("rbf", "white")))
setwd("~/Downloads/gptk")
library(gptk)
trueKern = kernCreate(x, list(type="cmpnd",comp=list("rbf", "white")))
K = kernCompute(trueKern, x)
model = gpCreate(dim(x)[2], 1, x, y, options)
dim(x)
x
y
options = gpOptions()
options$kern$comp = list("rbf","white")
lengthScale = c(0.05, 0.1, 0.25, 0.5, 1, 2, 4, 8, 16)
model = gpCreate(dim(x)[2], 1, x, y, options)
options = gpOptions()
options$kern$comp = list("rbf","white")
lengthScale = c(0.05, 0.1, 0.25, 0.5, 1, 2, 4, 8, 16)
## Inputs
trueKern = kernCreate(x, list(type="cmpnd",comp=list("rbf", "white")))
K = kernCompute(trueKern, x)
# y = scale(y,scale=FALSE)
model = gpCreate(dim(x)[2], 1, x, y, options)
model = gpCreate(dim(x)[2], 1, x, matrix(y,length(y),1), options)
inithypers = log(c(1/(lengthScale[1]), 1, model$kern$comp[[2]]$variance))
model = gpExpandParam(model, inithypers) ## This forces kernel computation.
ll_init = gpLogLikelihood(model) ## GP log-marginal likelihood for this model.
meanVar = gpPosteriorMeanVar(model, xtest, varsigma.return=TRUE) ## GP mean and variance.
# dev.new(); plot.new()
# gpPlot(model, xtest, meanVar$mu, meanVar$varsigma, ylim=c(-2.5,2.5), xlim=range(xtest), col='black')
# title(sprintf("l=%.4f, s_f=%.2f, s_n=%.2f\n GP log-likelihood=%.2f",
#               1/opthypers[1], opthypers[2], opthypers[3], ll_opt));
model = gpOptimise(model, display=TRUE, iters=400)
opthypers = gpExtractParam(model, only.values = FALSE);
opthypers = exp(opthypers);
opthypers
ll_opt = gpLogLikelihood(model)
ll_opt
trueKern = kernCreate(t(a), list("rbf"))
trueKern = kernCreate(t(a), "rbf")
K = kernCompute(trueKern, t(a))
# y = scale(y,scale=FALSE)
model = gpCreate(dim(t(a))[2], 1, t(a), matrix(y,length(y),1), options)
## hyperparameters: inverse-lengthscale, signal-variance, noise-variance.
inithypers = log(c(1/(lengthScale[1]), 1, model$kern$comp[[2]]$variance))
model = gpExpandParam(model, inithypers) ## This forces kernel computation.
ll_init = gpLogLikelihood(model) ## GP log-marginal likelihood for this model.
model = gpOptimise(model, display=TRUE, iters=400)
opthypers = gpExtractParam(model, only.values = FALSE);
opthypers = exp(opthypers);
opthypers
options = gpOptions()
# options$kern$comp = list("rbf","white")
options$kern = "rbf"
lengthScale = c(0.05, 0.1, 0.25, 0.5, 1, 2, 4, 8, 16)
## Inputs
# trueKern = kernCreate(t(a), list(type="cmpnd",comp=list("rbf", "white")))
trueKern = kernCreate(t(a), "rbf")
K = kernCompute(trueKern, t(a))
# y = scale(y,scale=FALSE)
model = gpCreate(dim(t(a))[2], 1, t(a), matrix(y,length(y),1), options)
inithypers = log(c(1/(lengthScale[1]), 1, model$kern$comp[[2]]$variance))
model = gpExpandParam(model, inithypers) ## This forces kernel computation.
ll_init = gpLogLikelihood(model) ## GP log-marginal likelihood for this model.
model = gpOptimise(model, display=TRUE, iters=400)
opthypers = gpExtractParam(model, only.values = FALSE);
opthypers = exp(opthypers);
opthypers
BMC = function(f,D,T,prior,w) {
b = prior$b; B = prior$B; A = diag(w[2:(D+1)])
kernel = function(x1,x2) {w[1]*exp(-1/2*sum(((x1-x2)/w[2:(D+1)])^2) )}
a = t(matrix(mvrnorm(n=T,b,B),T,D))
y = apply(a,2,f)
options = gpOptions()
# options$kern$comp = list("rbf","white")
options$kern = "rbf"
lengthScale = c(0.05, 0.1, 0.25, 0.5, 1, 2, 4, 8, 16)
## Inputs
# trueKern = kernCreate(t(a), list(type="cmpnd",comp=list("rbf", "white")))
trueKern = kernCreate(t(a), "rbf")
K = kernCompute(trueKern, t(a))
# y = scale(y,scale=FALSE)
model = gpCreate(dim(t(a))[2], 1, t(a), matrix(y,length(y),1), options)
## hyperparameters: inverse-lengthscale, signal-variance, noise-variance.
inithypers = log(c(1/(lengthScale[1]), 1, model$kern$comp[[2]]$variance))
model = gpExpandParam(model, inithypers) ## This forces kernel computation.
ll_init = gpLogLikelihood(model) ## GP log-marginal likelihood for this model.
model = gpOptimise(model, display=TRUE, iters=400)
opthypers = gpExtractParam(model, only.values = FALSE);
opthypers = exp(opthypers);
w = c(opthypers$variance,rep(opthypers$inverseWidth,D))
K = matrix(0,T,T)
for (i in 1:T) {
for (j in i:T) {
K[i,j] = kernel(a[,i],a[,j])
}
}
K = K + t(K) - Diagonal(T,diag(K))
func_z = function(u) {w[1] * det(solve(A)%*%B + diag(D))^(-1/2) * exp(-0.5* t(u - b) %*% solve(A+B) %*% (u-b))}
z = apply(a,2,func_z)
Ef = as.numeric(t(z) %*% solve(K,y))
Vf = as.numeric(w[1] * det(2*solve(A)%*%B + diag(D))^(-1/2) - t(z) %*% solve(K,z))
return(list(mean = Ef, var = Vf))
}
BMC = function(f,D,T,prior,w) {
b = prior$b; B = prior$B; A = diag(w[2:(D+1)])
a = t(matrix(mvrnorm(n=T,b,B),T,D))
y = apply(a,2,f)
options = gpOptions()
# options$kern$comp = list("rbf","white")
options$kern = "rbf"
lengthScale = c(0.05, 0.1, 0.25, 0.5, 1, 2, 4, 8, 16)
## Inputs
# trueKern = kernCreate(t(a), list(type="cmpnd",comp=list("rbf", "white")))
trueKern = kernCreate(t(a), "rbf")
K = kernCompute(trueKern, t(a))
# y = scale(y,scale=FALSE)
model = gpCreate(dim(t(a))[2], 1, t(a), matrix(y,length(y),1), options)
## hyperparameters: inverse-lengthscale, signal-variance, noise-variance.
inithypers = log(c(1/(lengthScale[1]), 1, model$kern$comp[[2]]$variance))
model = gpExpandParam(model, inithypers) ## This forces kernel computation.
ll_init = gpLogLikelihood(model) ## GP log-marginal likelihood for this model.
model = gpOptimise(model, display=TRUE, iters=400)
opthypers = gpExtractParam(model, only.values = FALSE);
opthypers = exp(opthypers);
w = c(opthypers$variance,rep(opthypers$inverseWidth,D))
kernel = function(x1,x2) {w[1]*exp(-1/2*sum(((x1-x2)/w[2:(D+1)])^2) )}
K = matrix(0,T,T)
for (i in 1:T) {
for (j in i:T) {
K[i,j] = kernel(a[,i],a[,j])
}
}
K = K + t(K) - Diagonal(T,diag(K))
func_z = function(u) {w[1] * det(solve(A)%*%B + diag(D))^(-1/2) * exp(-0.5* t(u - b) %*% solve(A+B) %*% (u-b))}
z = apply(a,2,func_z)
Ef = as.numeric(t(z) %*% solve(K,y))
Vf = as.numeric(w[1] * det(2*solve(A)%*%B + diag(D))^(-1/2) - t(z) %*% solve(K,z))
return(list(mean = Ef, var = Vf))
}
D=4; prior = list(b = rep(0,D), B = diag(D)); w = c(1,rep(2.4,D));
T_vec = round(seq(5,30,length.out=20)) # number of samples
mu= rep(0,D); Sigma = diag(D)
f = function(x) dmvnorm(x,mean=mu,sigma=Sigma)
M = solve(solve(Sigma) + solve(prior$B))
b = t((t(mu) %*% solve(Sigma) + t(prior$b) %*% solve(prior$B)) %*% M)
int = sqrt(det(M)/(2*pi*det(Sigma)*det(prior$B))) * exp(0.5*t(b) %*% solve(M) %*% b - 0.5*t(mu) %*% solve(Sigma) %*% mu
- 0.5*t(prior$b) %*% solve(prior$B) %*% prior$b )
Ef = c(); Vf = c()
for (t in 1:length(T_vec)) {
T = T_vec[t]
res = BMC(f,D,T,prior,w)
Ef[t] = res$mean
Vf[t] = res$var
}
b = prior$b; B = prior$B; A = diag(w[2:(D+1)])
a = t(matrix(mvrnorm(n=T,b,B),T,D))
y = apply(a,2,f)
options = gpOptions()
# options$kern$comp = list("rbf","white")
options$kern = "rbf"
lengthScale = c(0.05, 0.1, 0.25, 0.5, 1, 2, 4, 8, 16)
trueKern = kernCreate(t(a), "rbf")
K = kernCompute(trueKern, t(a))
# y = scale(y,scale=FALSE)
model = gpCreate(dim(t(a))[2], 1, t(a), matrix(y,length(y),1), options)
## hyperparameters: inverse-lengthscale, signal-variance, noise-variance.
inithypers = log(c(1/(lengthScale[1]), 1, model$kern$comp[[2]]$variance))
model = gpExpandParam(model, inithypers) ## This forces kernel computation.
ll_init = gpLogLikelihood(model) ## GP log-marginal likelihood for this model.
model = gpOptimise(model, display=TRUE, iters=400)
opthypers = gpExtractParam(model, only.values = FALSE);
opthypers = exp(opthypers);
w = c(opthypers$variance,rep(opthypers$inverseWidth,D))
opthypers
opthypers[2]
w = c(opthypers[2],rep(opthypers[1],D))
w
w = as.numeric(c(opthypers[2],rep(opthypers[1],D)))
w
BMC = function(f,D,T,prior,w) {
b = prior$b; B = prior$B; A = diag(w[2:(D+1)])
a = t(matrix(mvrnorm(n=T,b,B),T,D))
y = apply(a,2,f)
options = gpOptions()
# options$kern$comp = list("rbf","white")
options$kern = "rbf"
lengthScale = c(0.05, 0.1, 0.25, 0.5, 1, 2, 4, 8, 16)
## Inputs
# trueKern = kernCreate(t(a), list(type="cmpnd",comp=list("rbf", "white")))
trueKern = kernCreate(t(a), "rbf")
K = kernCompute(trueKern, t(a))
# y = scale(y,scale=FALSE)
model = gpCreate(dim(t(a))[2], 1, t(a), matrix(y,length(y),1), options)
## hyperparameters: inverse-lengthscale, signal-variance, noise-variance.
inithypers = log(c(1/(lengthScale[1]), 1, model$kern$comp[[2]]$variance))
model = gpExpandParam(model, inithypers) ## This forces kernel computation.
ll_init = gpLogLikelihood(model) ## GP log-marginal likelihood for this model.
model = gpOptimise(model, display=TRUE, iters=400)
opthypers = gpExtractParam(model, only.values = FALSE);
opthypers = exp(opthypers);
w = as.numeric(c(opthypers[2],rep(opthypers[1],D)))
kernel = function(x1,x2) {w[1]*exp(-1/2*sum(((x1-x2)/w[2:(D+1)])^2) )}
K = matrix(0,T,T)
for (i in 1:T) {
for (j in i:T) {
K[i,j] = kernel(a[,i],a[,j])
}
}
K = K + t(K) - Diagonal(T,diag(K))
func_z = function(u) {w[1] * det(solve(A)%*%B + diag(D))^(-1/2) * exp(-0.5* t(u - b) %*% solve(A+B) %*% (u-b))}
z = apply(a,2,func_z)
Ef = as.numeric(t(z) %*% solve(K,y))
Vf = as.numeric(w[1] * det(2*solve(A)%*%B + diag(D))^(-1/2) - t(z) %*% solve(K,z))
return(list(mean = Ef, var = Vf))
}
D=4; prior = list(b = rep(0,D), B = diag(D)); w = c(1,rep(2.4,D));
T_vec = round(seq(5,30,length.out=20)) # number of samples
mu= rep(0,D); Sigma = diag(D)
f = function(x) dmvnorm(x,mean=mu,sigma=Sigma)
M = solve(solve(Sigma) + solve(prior$B))
b = t((t(mu) %*% solve(Sigma) + t(prior$b) %*% solve(prior$B)) %*% M)
int = sqrt(det(M)/(2*pi*det(Sigma)*det(prior$B))) * exp(0.5*t(b) %*% solve(M) %*% b - 0.5*t(mu) %*% solve(Sigma) %*% mu
- 0.5*t(prior$b) %*% solve(prior$B) %*% prior$b )
Ef = c(); Vf = c()
for (t in 1:length(T_vec)) {
T = T_vec[t]
res = BMC(f,D,T,prior,w)
Ef[t] = res$mean
Vf[t] = res$var
}
Ef
plot(T_vec,abs(Ef-int))
BMC = function(f,D,T,prior,w) {
b = prior$b; B = prior$B; A = diag(w[2:(D+1)])
a = t(matrix(mvrnorm(n=T,b,B),T,D))
y = apply(a,2,f)
options = gpOptions()
# options$kern$comp = list("rbf","white")
options$kern = "rbf"
lengthScale = c(0.05, 0.1, 0.25, 0.5, 1, 2, 4, 8, 16)
## Inputs
# trueKern = kernCreate(t(a), list(type="cmpnd",comp=list("rbf", "white")))
trueKern = kernCreate(t(a), "rbf")
K = kernCompute(trueKern, t(a))
# y = scale(y,scale=FALSE)
model = gpCreate(dim(t(a))[2], 1, t(a), matrix(y,length(y),1), options)
## hyperparameters: inverse-lengthscale, signal-variance, noise-variance.
inithypers = log(c(1/(lengthScale[1]), 1, model$kern$comp[[2]]$variance))
model = gpExpandParam(model, inithypers) ## This forces kernel computation.
ll_init = gpLogLikelihood(model) ## GP log-marginal likelihood for this model.
model = gpOptimise(model, display=TRUE, iters=400)
opthypers = gpExtractParam(model, only.values = FALSE);
opthypers = exp(opthypers);
w = as.numeric(c(opthypers[1],rep(opthypers[2],D)))
kernel = function(x1,x2) {w[1]*exp(-1/2*sum(((x1-x2)/w[2:(D+1)])^2) )}
K = matrix(0,T,T)
for (i in 1:T) {
for (j in i:T) {
K[i,j] = kernel(a[,i],a[,j])
}
}
K = K + t(K) - Diagonal(T,diag(K))
func_z = function(u) {w[1] * det(solve(A)%*%B + diag(D))^(-1/2) * exp(-0.5* t(u - b) %*% solve(A+B) %*% (u-b))}
z = apply(a,2,func_z)
Ef = as.numeric(t(z) %*% solve(K,y))
Vf = as.numeric(w[1] * det(2*solve(A)%*%B + diag(D))^(-1/2) - t(z) %*% solve(K,z))
return(list(mean = Ef, var = Vf))
}
D=4; prior = list(b = rep(0,D), B = diag(D)); w = c(1,rep(2.4,D));
T_vec = round(seq(5,30,length.out=20)) # number of samples
mu= rep(0,D); Sigma = diag(D)
f = function(x) dmvnorm(x,mean=mu,sigma=Sigma)
M = solve(solve(Sigma) + solve(prior$B))
b = t((t(mu) %*% solve(Sigma) + t(prior$b) %*% solve(prior$B)) %*% M)
int = sqrt(det(M)/(2*pi*det(Sigma)*det(prior$B))) * exp(0.5*t(b) %*% solve(M) %*% b - 0.5*t(mu) %*% solve(Sigma) %*% mu
- 0.5*t(prior$b) %*% solve(prior$B) %*% prior$b )
Ef = c(); Vf = c()
for (t in 1:length(T_vec)) {
T = T_vec[t]
res = BMC(f,D,T,prior,w)
Ef[t] = res$mean
Vf[t] = res$var
}
Ef
plot(T_vec,abs(Ef-int))
D=4; prior = list(b = rep(0,D), B = diag(D)); w = c(1,rep(2.4,D));
T_vec = round(seq(5,100,length.out=50)) # number of samples
mu= rep(0,D); Sigma = diag(D)
f = function(x) dmvnorm(x,mean=mu,sigma=Sigma)
M = solve(solve(Sigma) + solve(prior$B))
b = t((t(mu) %*% solve(Sigma) + t(prior$b) %*% solve(prior$B)) %*% M)
int = sqrt(det(M)/(2*pi*det(Sigma)*det(prior$B))) * exp(0.5*t(b) %*% solve(M) %*% b - 0.5*t(mu) %*% solve(Sigma) %*% mu
- 0.5*t(prior$b) %*% solve(prior$B) %*% prior$b )
Ef = c(); Vf = c()
for (t in 1:length(T_vec)) {
T = T_vec[t]
res = BMC(f,D,T,prior,w)
Ef[t] = res$mean
Vf[t] = res$var
}
Ef
plot(T_vec,abs(Ef-int))
int
plot(T_vec,Vf)
f = function(x) {0.1*x^2 - 0.1*x + 0.5*sin(2*x)}
D=4; prior = list(b = rep(0,D), B = diag(D)); w = c(1,rep(2.4,D));
T_vec = round(seq(1,50,length.out=50)) # number of samples
mu= rep(0,D); Sigma = diag(D)
f = function(x) dmvnorm(x,mean=mu,sigma=Sigma)
M = solve(solve(Sigma) + solve(prior$B))
b = t((t(mu) %*% solve(Sigma) + t(prior$b) %*% solve(prior$B)) %*% M)
int = sqrt(det(M)/(2*pi*det(Sigma)*det(prior$B))) * exp(0.5*t(b) %*% solve(M) %*% b - 0.5*t(mu) %*% solve(Sigma) %*% mu
- 0.5*t(prior$b) %*% solve(prior$B) %*% prior$b )
Ef = c(); Vf = c()
for (t in 1:length(T_vec)) {
T = T_vec[t]
res = BMC(f,D,T,prior,w)
Ef[t] = res$mean
Vf[t] = res$var
}
plot(T_vec,abs(Ef-int))
plot(T_vec,Vf)
plot(T_vec,abs(Ef-int))
Ef
